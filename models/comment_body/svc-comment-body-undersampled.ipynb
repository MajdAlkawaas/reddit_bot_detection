{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split, learning_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Data\n",
    "60% training, 20% validation, and 20% testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Move these two functions to a shared file for helper functions\n",
    "def unPickleData(filename):\n",
    "  with open(filename,'rb') as f: arr = pickle.load(f)\n",
    "  return arr\n",
    "\n",
    "def getDataPath(dirname,filename):\n",
    "  return os.path.join(os.path.abspath(os.path.join(os.getcwd(), os.pardir, os.pardir)),\"processed_data\", dirname,filename)\n",
    "\n",
    "X = unPickleData(getDataPath(\"comments\",\"X_comments.pkl\"))\n",
    "y = unPickleData(getDataPath(\"comments\",\"Y_comments.pkl\"))\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size = 0.4, random_state=15, stratify=y)\n",
    "X_val,   X_test, y_val,   y_test = train_test_split(X_temp, y_temp, test_size = 0.5, random_state=15, stratify=y_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove both lists to save up  memory\n",
    "X = np.load(\"X_comment.npy\")\n",
    "y = np.load(\"y_comment.npy\")\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size = 0.4, random_state=15, stratify=y)\n",
    "X_val,   X_test, y_val,   y_test = train_test_split(X_temp, y_temp, test_size = 0.5, random_state=15, stratify=y_temp)\n",
    "number_features = len(X_train[0])\n",
    "\n",
    "\n",
    "del X\n",
    "del y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(kernel='poly', verbose=True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_poly = SVC(kernel=\"poly\", verbose=True)\n",
    "model_poly.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"svm_model_poly.pkl\", 'wb') as file:\n",
    "    pickle.dump(model_poly, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"svm_model_poly.pkl\", 'rb') as file:\n",
    "    model_poly = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes, train_scores, test_scores, fit_times, _ = learning_curve(model_poly, \n",
    "                                                                    X_train, \n",
    "                                                                    y_train, \n",
    "                                                                    # scoring='accuracy', \n",
    "                                                                    cv=5, \n",
    "                                                                    return_times=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {\"C\":np.logspace(-3,3,100)}\n",
    "\n",
    "search = GridSearchCV(model_poly,grid, cv=10)\n",
    "search.fit(X_val,y_val)\n",
    "\n",
    "print(\"Tuned hpyerparameters :(best parameters) \",search.best_params_)\n",
    "print(\"Accuracy :\",search.best_score_)\n",
    "\n",
    "best_model_lin = search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {'C':np.logspace(-3,3,10), 'degree':[1,2,3,4,5], 'gamma':['scale', 'auto'], 'coef0':np.logspace(0,1,10)}\n",
    "\n",
    "search = GridSearchCV(model_poly,grid,cv=10)\n",
    "search.fit(X_val, y_val)\n",
    "\n",
    "print(\"Tuned hpyerparameters :(best parameters) \",search.best_params_)\n",
    "print(\"Accuracy :\",search.best_score_)\n",
    "\n",
    "best_model_poly = search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excluding the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      7501\n",
      "           1       0.99      0.65      0.79      2618\n",
      "\n",
      "    accuracy                           0.91     10119\n",
      "   macro avg       0.94      0.82      0.86     10119\n",
      "weighted avg       0.92      0.91      0.90     10119\n",
      "\n",
      "Accuracy:  0.9076983891688902\n"
     ]
    }
   ],
   "source": [
    "# y_pred = best_model_poly.predict(X_test)\n",
    "y_pred = model_poly.predict(X_test)\n",
    "\n",
    "print(sklearn.metrics.classification_report(y_test,y_pred))\n",
    "print(\"Accuracy: \", sklearn.metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Including the validation set\n",
    "Because of the lack of representation of the class \"bot\", especially in the testing data, the model reflects poor results when it comes to the recall and f-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94     15001\n",
      "           1       0.99      0.65      0.78      5237\n",
      "\n",
      "    accuracy                           0.91     20238\n",
      "   macro avg       0.94      0.82      0.86     20238\n",
      "weighted avg       0.92      0.91      0.90     20238\n",
      "\n",
      "Accuracy:  0.9068583852159304\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_poly.predict(np.concatenate((X_test,X_val)))\n",
    "print(sklearn.metrics.classification_report(np.concatenate((y_test,y_val)),y_pred))\n",
    "print(\"Accuracy: \", sklearn.metrics.accuracy_score(np.concatenate((y_test,y_val)), y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0f8db473d6762dfb6f9dcd7989df9714501dfc9335e8a68c24282034a9bd8d9b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
