{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Data\n",
    "60% training, 20% validation, and 20% testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Move these two functions to a shared file for helper functions\n",
    "def unPickleData(filename):\n",
    "  with open(filename,'rb') as f: arr = pickle.load(f)\n",
    "  return arr\n",
    "\n",
    "def getDataPath(dirname,filename):\n",
    "  return os.path.join(os.path.abspath(os.path.join(os.getcwd(), os.pardir, os.pardir)),\"processed_data\", dirname,filename)\n",
    "\n",
    "x_data = unPickleData(getDataPath(\"comments\",\"X_comments_sub.pkl\"))\n",
    "y_data = unPickleData(getDataPath(\"comments\",\"Y_comments_sub.pkl\"))\n",
    "\n",
    "n = len(x_data)\n",
    "x_data_training = x_data[:int(0.6*n)]\n",
    "x_data_validation = x_data[int(0.6*n):int(0.8*n)]\n",
    "x_data_testing = x_data[int(0.8*n):]\n",
    "\n",
    "y_data_training = y_data[:int(0.6*n)]\n",
    "y_data_validation = y_data[int(0.6*n):int(0.8*n)]\n",
    "y_data_testing = y_data[int(0.8*n):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(multi_class='ovr', solver='liblinear')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(multi_class='ovr',solver=\"liblinear\") \n",
    "model.fit(x_data_training, y_data_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned hpyerparameters :(best parameters)  {'C': 17.47528400007683, 'penalty': 'l2'}\n",
      "Accuracy : 0.8732804232804232\n"
     ]
    }
   ],
   "source": [
    "grid = {\"C\":np.logspace(-3,3,100), \"penalty\":[\"l1\",\"l2\"]}\n",
    "\n",
    "search = GridSearchCV(model,grid,cv=10)\n",
    "search.fit(x_data_validation,y_data_validation)\n",
    "\n",
    "print(\"Tuned hpyerparameters :(best parameters) \",search.best_params_)\n",
    "print(\"Accuracy :\",search.best_score_)\n",
    "\n",
    "best_model = search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excluding the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.98      0.92       229\n",
      "           1       0.76      0.33      0.46        48\n",
      "\n",
      "    accuracy                           0.87       277\n",
      "   macro avg       0.82      0.66      0.69       277\n",
      "weighted avg       0.86      0.87      0.84       277\n",
      "\n",
      "Accuracy:  0.8664259927797834\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_model.predict(x_data_testing)\n",
    "\n",
    "print(sklearn.metrics.classification_report(y_data_testing,y_pred))\n",
    "print(\"Accuracy: \", sklearn.metrics.accuracy_score(y_data_testing, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Including the validation set\n",
    "Because of the lack of representation of the class \"bot\", especially in the testing data, the model reflects poor results when it comes to the recall and f-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.95       459\n",
      "           1       0.88      0.52      0.65        94\n",
      "\n",
      "    accuracy                           0.91       553\n",
      "   macro avg       0.89      0.75      0.80       553\n",
      "weighted avg       0.90      0.91      0.90       553\n",
      "\n",
      "Accuracy:  0.9059674502712477\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_model.predict(np.concatenate((x_data_testing,x_data_validation))\n",
    ")\n",
    "print(sklearn.metrics.classification_report(np.concatenate((y_data_testing,y_data_validation)),y_pred))\n",
    "print(\"Accuracy: \", sklearn.metrics.accuracy_score(np.concatenate((y_data_testing,y_data_validation)), y_pred))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0f8db473d6762dfb6f9dcd7989df9714501dfc9335e8a68c24282034a9bd8d9b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
