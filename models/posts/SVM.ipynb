{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unPickleData(filename):\n",
    "  with open(filename,'rb') as f: arr = pickle.load(f)\n",
    "  return arr\n",
    "\n",
    "def getDataPath(dirname,filename):\n",
    "  return os.path.join(os.path.abspath(os.path.join(os.getcwd(), os.pardir, os.pardir)),\"processed_data\", dirname,filename)\n",
    "\n",
    "x_data = unPickleData(getDataPath(\"posts\",\"X_posts.pkl\"))\n",
    "y_data = unPickleData(getDataPath(\"posts\",\"Y_posts.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2000 3000 4000 5000 6000 7000 8000 9000 11000 12000 13000 14000 15000 16000 17000 18000 19000 20000 21000 22000 23000 class 0: 20000\n",
      "class 1: 9114\n"
     ]
    }
   ],
   "source": [
    "X, y = [], []\n",
    "Class0_max_count = 20000\n",
    "for i in range(len(x_data)):\n",
    "    if y_data[i] == 0: \n",
    "        if Class0_max_count > 0:\n",
    "            X.append(x_data[i])\n",
    "            y.append(y_data[i])\n",
    "            if i%1000 == 0: print(i, end=\" \")\n",
    "            Class0_max_count -= 1 \n",
    "    else:\n",
    "        X.append(x_data[i])\n",
    "        y.append(y_data[i])\n",
    "\n",
    "np_y = np.array(y)\n",
    "print(\"class 0:\", len(np_y[np_y==0]))\n",
    "print(\"class 1:\", len(np_y[np_y==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_rem, y_train, y_rem = train_test_split(X,y, train_size=0.6 , random_state= 42)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_rem,y_rem, test_size=0.5 , random_state= 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM trainig & Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV 1/5; 1/4] START C=0.001.....................................................\n",
      "[CV 1/5; 1/4] END C=0.001; accuracy: (test=0.685) f1_micro: (test=0.685) total time=15.6min\n",
      "[CV 2/5; 1/4] START C=0.001.....................................................\n",
      "[CV 2/5; 1/4] END C=0.001; accuracy: (test=0.685) f1_micro: (test=0.685) total time=34.4min\n",
      "[CV 3/5; 1/4] START C=0.001.....................................................\n",
      "[CV 3/5; 1/4] END C=0.001; accuracy: (test=0.685) f1_micro: (test=0.685) total time=14.5min\n",
      "[CV 4/5; 1/4] START C=0.001.....................................................\n",
      "[CV 4/5; 1/4] END C=0.001; accuracy: (test=0.685) f1_micro: (test=0.685) total time=15.1min\n",
      "[CV 5/5; 1/4] START C=0.001.....................................................\n",
      "[CV 5/5; 1/4] END C=0.001; accuracy: (test=0.685) f1_micro: (test=0.685) total time=16.1min\n",
      "[CV 1/5; 2/4] START C=0.01......................................................\n",
      "[CV 1/5; 2/4] END C=0.01; accuracy: (test=0.685) f1_micro: (test=0.685) total time=17.7min\n",
      "[CV 2/5; 2/4] START C=0.01......................................................\n",
      "[CV 2/5; 2/4] END C=0.01; accuracy: (test=0.685) f1_micro: (test=0.685) total time=17.6min\n",
      "[CV 3/5; 2/4] START C=0.01......................................................\n",
      "[CV 3/5; 2/4] END C=0.01; accuracy: (test=0.685) f1_micro: (test=0.685) total time=94.4min\n",
      "[CV 4/5; 2/4] START C=0.01......................................................\n",
      "[CV 4/5; 2/4] END C=0.01; accuracy: (test=0.685) f1_micro: (test=0.685) total time=84.8min\n",
      "[CV 5/5; 2/4] START C=0.01......................................................\n",
      "[CV 5/5; 2/4] END C=0.01; accuracy: (test=0.685) f1_micro: (test=0.685) total time=17.3min\n",
      "[CV 1/5; 3/4] START C=0.1.......................................................\n",
      "[CV 1/5; 3/4] END C=0.1; accuracy: (test=0.753) f1_micro: (test=0.753) total time=18.2min\n",
      "[CV 2/5; 3/4] START C=0.1.......................................................\n",
      "[CV 2/5; 3/4] END C=0.1; accuracy: (test=0.758) f1_micro: (test=0.758) total time=17.0min\n",
      "[CV 3/5; 3/4] START C=0.1.......................................................\n",
      "[CV 3/5; 3/4] END C=0.1; accuracy: (test=0.760) f1_micro: (test=0.760) total time=18.4min\n",
      "[CV 4/5; 3/4] START C=0.1.......................................................\n",
      "[CV 4/5; 3/4] END C=0.1; accuracy: (test=0.759) f1_micro: (test=0.759) total time=17.1min\n",
      "[CV 5/5; 3/4] START C=0.1.......................................................\n",
      "[CV 5/5; 3/4] END C=0.1; accuracy: (test=0.754) f1_micro: (test=0.754) total time=16.2min\n",
      "[CV 1/5; 4/4] START C=1.........................................................\n",
      "[CV 1/5; 4/4] END C=1; accuracy: (test=0.793) f1_micro: (test=0.793) total time=13.9min\n",
      "[CV 2/5; 4/4] START C=1.........................................................\n",
      "[CV 2/5; 4/4] END C=1; accuracy: (test=0.808) f1_micro: (test=0.808) total time=14.0min\n",
      "[CV 3/5; 4/4] START C=1.........................................................\n",
      "[CV 3/5; 4/4] END C=1; accuracy: (test=0.809) f1_micro: (test=0.809) total time=77.7min\n",
      "[CV 4/5; 4/4] START C=1.........................................................\n",
      "[CV 4/5; 4/4] END C=1; accuracy: (test=0.813) f1_micro: (test=0.813) total time=15.3min\n",
      "[CV 5/5; 4/4] START C=1.........................................................\n",
      "[CV 5/5; 4/4] END C=1; accuracy: (test=0.810) f1_micro: (test=0.810) total time=15.6min\n",
      "For Linear SVM:\n",
      "Best Estimator: SVC(C=1, kernel='linear')\n",
      "F-measure = 0.8066183556908568\n",
      "Accuracy = 0.8066183556908568\n"
     ]
    }
   ],
   "source": [
    "parameters = {'C':[0.001,0.01,0.1, 1]}\n",
    "linearSVM = SVC(kernel=\"linear\")\n",
    "linearClassifier = GridSearchCV(linearSVM, parameters, scoring = ['f1_micro','accuracy'], cv=5, refit='f1_micro' , verbose = 10)\n",
    "linearClassifier.fit(X_train, y_train)\n",
    "\n",
    "bestLinearClassifier = linearClassifier.best_estimator_\n",
    "\n",
    "print(\"For Linear SVM:\")\n",
    "print(f\"Best Estimator: {linearClassifier.best_estimator_}\")\n",
    "print(f\"F-measure = {linearClassifier.best_score_}\")\n",
    "print(f\"Accuracy = {max(linearClassifier.cv_results_['mean_test_f1_micro'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.87      3993\n",
      "           1       0.80      0.55      0.65      1830\n",
      "\n",
      "    accuracy                           0.81      5823\n",
      "   macro avg       0.81      0.74      0.76      5823\n",
      "weighted avg       0.81      0.81      0.80      5823\n",
      "\n",
      "Accuracy:  0.8140133951571354\n",
      "f-measure = 0.8140133951571356\n"
     ]
    }
   ],
   "source": [
    "y_pred = bestLinearClassifier.predict(X_test)\n",
    "\n",
    "print(sklearn.metrics.classification_report(y_test,y_pred))\n",
    "print(\"Accuracy: \", sklearn.metrics.accuracy_score(y_test, y_pred))\n",
    "print(f\"f-measure = {sklearn.metrics.f1_score(y_test, y_pred, average='micro')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSavedModelPath(dirname,filename):\n",
    "  return os.path.join(os.path.abspath(os.path.join(os.getcwd(), os.pardir, os.pardir)),\"savedModels\", dirname,filename)\n",
    "\n",
    "with open(getSavedModelPath(\"posts\",\"SVM.pkl\"), 'wb') as f:\n",
    "    pickle.dump(bestLinearClassifier,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[learning_curve] Training set sizes: [  157   474   792  1110  1427  1745  2062  2380  2698  3015  3333  3651\n",
      "  3968  4286  4604  4921  5239  5556  5874  6192  6509  6827  7145  7462\n",
      "  7780  8097  8415  8733  9050  9368  9686 10003 10321 10638 10956 11274\n",
      " 11591 11909 12227 12544 12862 13179 13497 13815 14132 14450 14768 15085\n",
      " 15403 15721]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_size, train_score, test_scores = learning_curve(bestLinearClassifier, X_train, y_train, cv = 10, scoring='accuracy', n_jobs=1, train_sizes=np.linspace(0.01, 1, 50), verbose=1)\n",
    "mean_train = np.mean(train_score , axis = 1)\n",
    "mean_test = np.mean(test_scores , axis = 1)\n",
    "plt.plot(train_size, 1-mean_train, label='Training score')\n",
    "plt.plot(train_size, 1-mean_test, label='Cross-validation score')\n",
    "plt.xlabel('Training Size')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Learning Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "de6ff951bef0339bc88a2ed79bdf78947cbc6531509306936c69548d8895ab6c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
