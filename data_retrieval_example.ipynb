{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Retrieval Example\n",
    "\n",
    "## requirements:\n",
    "- instal praw using the following command `!pip install praw`. Don't use conda for this specific model.\n",
    "- instal beautifulsoup using the following command `!pip install bs4`\n",
    "- instal requests if you don't have in your development environment \n",
    "\n",
    "## References:\n",
    "- https://towardsdatascience.com/how-to-use-the-reddit-api-in-python-5e05ddfd1e5c\n",
    "- https://www.reddit.com/dev/api\n",
    "- https://praw.readthedocs.io/en/stable/index.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "import requests\n",
    "import bs4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to the reddit API using `requests`\n",
    "\n",
    "### Steps:\n",
    "- create an app on reddit to acquire the access credentials:\n",
    "    - `PASSWORD` password of the reddit account used to create the app\n",
    "    - `USERNAME` username of the reddit account used to create the app\n",
    "    - `CLIENT_ID` acquired after creating the app\n",
    "    - `SECRET_TOKEN` acquired after creating the app\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PASSWORD = 'j=HUZ`6S8B'\n",
    "USERNAME = 'CMPS287_project'\n",
    "CLIENT_ID = 'd5w9jc7mmyeLEL2DG1wtxg'\n",
    "SECRET_TOKEN = 'HIOuTew4HunOVSJeFT47Yi4sCkdBCA' \n",
    "# note that CLIENT_ID refers to 'personal use script' and SECRET_TOKEN to 'token'\n",
    "auth = requests.auth.HTTPBasicAuth(CLIENT_ID, SECRET_TOKEN)\n",
    "\n",
    "# here we pass our login method (password), username, and password\n",
    "data = {'grant_type': 'password',\n",
    "        'username': USERNAME,\n",
    "        'password': PASSWORD }\n",
    "\n",
    "# setup our header info, which gives reddit a brief description of our app\n",
    "headers = {'User-Agent': 'MyAPI/0.0.1'}\n",
    "\n",
    "# send our request for an OAuth token\n",
    "res = requests.post('https://www.reddit.com/api/v1/access_token',\n",
    "                    auth=auth, data=data, headers=headers)\n",
    "\n",
    "# convert response to JSON and pull access_token value\n",
    "TOKEN = res.json()['access_token']\n",
    "\n",
    "# add authorization to our headers dictionary\n",
    "headers = {**headers, **{'Authorization': f\"bearer {TOKEN}\"}}\n",
    "\n",
    "# while the token is valid (~2 hours) we just add headers=headers to our requests\n",
    "response_josn = requests.get('https://oauth.reddit.com/api/v1/me', headers=headers).json()\n",
    "\n",
    "# To see the response just print response_json\n",
    "# print(response_josn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "hot = \"https://oauth.reddit.com/r/python/hot\"\n",
    "\n",
    "\n",
    "# make a request for the trending posts in /r/Python\n",
    "res = requests.get(\"https://oauth.reddit.com/r/python/hot\",\n",
    "                   headers=headers)\n",
    "\n",
    "df = pd.DataFrame()  # initialize dataframe\n",
    "\n",
    "# loop through each post retrieved from GET request\n",
    "for post in res.json()['data']['children']:\n",
    "    # append relevant data to dataframe\n",
    "    df = df.append({\n",
    "        'subreddit': post['data']['subreddit'],\n",
    "        'title': post['data']['title'],\n",
    "        'selftext': post['data']['selftext'],\n",
    "        'upvote_ratio': post['data']['upvote_ratio'],\n",
    "        'ups': post['data']['ups'],\n",
    "        'downs': post['data']['downs'],\n",
    "        'score': post['data']['score']\n",
    "    }, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>downs</th>\n",
       "      <th>score</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>ups</th>\n",
       "      <th>upvote_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Tell /r/python what you're working on this wee...</td>\n",
       "      <td>Python</td>\n",
       "      <td>Sunday Daily Thread: What's everyone working o...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Have some burning questions on advanced Python...</td>\n",
       "      <td>Python</td>\n",
       "      <td>Tuesday Daily Thread: Advanced questions</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Python just makes so much freaking sense! LOVI...</td>\n",
       "      <td>Python</td>\n",
       "      <td>Learning Python</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td></td>\n",
       "      <td>Python</td>\n",
       "      <td>I'm presenting live in 6 hours at Microsoft Re...</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>551.0</td>\n",
       "      <td></td>\n",
       "      <td>Python</td>\n",
       "      <td>Python f-strings Are More Powerful Than You Mi...</td>\n",
       "      <td>551.0</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   downs  score                                           selftext subreddit  \\\n",
       "0    0.0    6.0  Tell /r/python what you're working on this wee...    Python   \n",
       "1    0.0    4.0  Have some burning questions on advanced Python...    Python   \n",
       "2    0.0   17.0  Python just makes so much freaking sense! LOVI...    Python   \n",
       "3    0.0   79.0                                                       Python   \n",
       "4    0.0  551.0                                                       Python   \n",
       "\n",
       "                                               title    ups  upvote_ratio  \n",
       "0  Sunday Daily Thread: What's everyone working o...    6.0          0.88  \n",
       "1           Tuesday Daily Thread: Advanced questions    4.0          0.84  \n",
       "2                                    Learning Python   17.0          0.76  \n",
       "3  I'm presenting live in 6 hours at Microsoft Re...   79.0          0.87  \n",
       "4  Python f-strings Are More Powerful Than You Mi...  551.0          0.93  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jazinthapiper\n",
      "aZestyEggRoll\n",
      "highfelics\n",
      "patty3123\n",
      "Spczippo\n",
      "Bufflegs69\n",
      "foobarney\n",
      "mekkanik\n",
      "patricknicoconc\n",
      "mel7it\n",
      "NeoArdipithecus\n",
      "SqueakyFarts99\n",
      "wseQ\n",
      "PJ-Beans\n",
      "tabacdk\n",
      "marccee4\n",
      "Xeu1009X10\n",
      "Ca1yp50\n",
      "kvnsmbrt\n",
      "Voodoohigh\n",
      "ryohazuki224\n",
      "QuasiQuokka\n",
      "CivitasBlu\n",
      "plurprincess77\n",
      "_Jacques\n"
     ]
    }
   ],
   "source": [
    "# getting usernames of the hot posts\n",
    "authors_contributors = \"https://oauth.reddit.com/r/explainlikeimfive/hot\"\n",
    "\n",
    "# make a request for the trending posts in /r/Python\n",
    "res = requests.get(authors_contributors, headers=headers)\n",
    "\n",
    "respons_json = res.json()['data']['children']\n",
    "\n",
    "for i in range(len(respons_json)):\n",
    "    print(respons_json[i]['data']['author'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example using praw library\n",
    "- praw library is the python Reddit API wrapper\n",
    "- We use the same access credentials we used in the previous example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Ask Anything Monday - Weekly Thread\n",
      "PyStockWatch - a GUI that displays NYSE data.\n",
      "If you had $3,500 to learn Python, how would you spend it?\n",
      "Script to watch anime from command line\n",
      "A question about for loops\n",
      "If I use requests.get(url) in a try block, would it be reasonable to catch all the exceptions listed here?\n",
      "Pyperclip module installed but not working?\n",
      "Although I have created the variable and given it a value it says that it is being referenced before it has been created is there a way to fix this?\n",
      "How can I be successful with learning Python and the “100 Days of Code” course?\n",
      "Heroes and Villains\n"
     ]
    }
   ],
   "source": [
    "reddit = praw.Reddit(client_id     = CLIENT_ID,\n",
    "                     client_secret = SECRET_TOKEN,\n",
    "                     user_agent    = 'MyAPI/0.0.1')\n",
    "\n",
    "# To test if your instance is working use:\n",
    "print(reddit.read_only) # Output: True\n",
    "\n",
    "for submission in reddit.subreddit(\"learnpython\").hot(limit=10):\n",
    "    print(submission.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "autowikibot/botlist\n",
      "autowikibot/commandlist\n",
      "autowikibot/config/description\n",
      "autowikibot/config/sidebar\n",
      "autowikibot/config/stylesheet\n",
      "autowikibot/config/submit_text\n",
      "autowikibot/css\n",
      "autowikibot/excludedsubs\n",
      "autowikibot/index\n",
      "autowikibot/livelists\n",
      "autowikibot/modfaqs\n",
      "autowikibot/nsfwtag\n",
      "autowikibot/planned\n",
      "autowikibot/redditbots\n",
      "autowikibot/rootonlysubs\n",
      "autowikibot/statistics\n",
      "autowikibot/summon\n",
      "autowikibot/summononlysubs\n",
      "autowikibot/userblacklist\n"
     ]
    }
   ],
   "source": [
    "#  getting the wikipages of the r/autowikibot subreddit\n",
    "#  link to the subreddit http://www.reddit.com/user/autowikibot\n",
    "\n",
    "for wikipage in reddit.subreddit(\"autowikibot\").wiki:\n",
    "    print(wikipage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the content of a specific wikipage in the r/autowikibot subreddit\n",
    "# link to the wikipage we are requesting https://www.reddit.com/r/autowikibot/wiki/redditbots\n",
    "wikipage = reddit.subreddit(\"autowikibot\").wiki[\"redditbots\"]\n",
    "\n",
    "# print the content of the page\n",
    "# print(wikipage.content_md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "399"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://www.reddit.com/r/autowikibot/wiki/redditbots\"\n",
    "# Headers to mimic a browser visit\n",
    "headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "\n",
    "# Returns a requests.models.Response object\n",
    "page = requests.get(url, headers=headers)\n",
    "\n",
    "soup = bs4.BeautifulSoup(page.text, 'html.parser')\n",
    "a_tags = soup.select(\"table tbody td a\")\n",
    "\n",
    "bots_usrnames = []\n",
    "for i in range(len(a_tags)):\n",
    "    href = a_tags[i].attrs['href']\n",
    "    if href.startswith('/u/'):\n",
    "        # print(href)\n",
    "        bots_usrnames.append(href)\n",
    "len(bots_usrnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using BeautifulSoup and Pandas\n",
    "\n",
    "- Pandas provide a `read_html()` function that takes a webpage url and returns a list of dataframes created form the tables that exist in the said webpage.\n",
    "- I am using here bs4 to parse the webpage and passing the soup object which is the parsed html page I am doing this instead of passing the url to the function because the parser that is integrated with the function is bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>downs</th>\n",
       "      <th>score</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>ups</th>\n",
       "      <th>upvote_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Tell /r/python what you're working on this wee...</td>\n",
       "      <td>Python</td>\n",
       "      <td>Sunday Daily Thread: What's everyone working o...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Have some burning questions on advanced Python...</td>\n",
       "      <td>Python</td>\n",
       "      <td>Tuesday Daily Thread: Advanced questions</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Python just makes so much freaking sense! LOVI...</td>\n",
       "      <td>Python</td>\n",
       "      <td>Learning Python</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td></td>\n",
       "      <td>Python</td>\n",
       "      <td>I'm presenting live in 6 hours at Microsoft Re...</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>551.0</td>\n",
       "      <td></td>\n",
       "      <td>Python</td>\n",
       "      <td>Python f-strings Are More Powerful Than You Mi...</td>\n",
       "      <td>551.0</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   downs  score                                           selftext subreddit  \\\n",
       "0    0.0    6.0  Tell /r/python what you're working on this wee...    Python   \n",
       "1    0.0    4.0  Have some burning questions on advanced Python...    Python   \n",
       "2    0.0   17.0  Python just makes so much freaking sense! LOVI...    Python   \n",
       "3    0.0   79.0                                                       Python   \n",
       "4    0.0  551.0                                                       Python   \n",
       "\n",
       "                                               title    ups  upvote_ratio  \n",
       "0  Sunday Daily Thread: What's everyone working o...    6.0          0.88  \n",
       "1           Tuesday Daily Thread: Advanced questions    4.0          0.84  \n",
       "2                                    Learning Python   17.0          0.76  \n",
       "3  I'm presenting live in 6 hours at Microsoft Re...   79.0          0.87  \n",
       "4  Python f-strings Are More Powerful Than You Mi...  551.0          0.93  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_list_bot_usrnames = []\n",
    "\n",
    "# Parsing a webpage that has one table of bot accounts.\n",
    "page = requests.get('https://www.reddit.com/r/autowikibot/wiki/redditbots', headers=headers)\n",
    "soup = bs4.BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "# Passing the parsed page as text to the function\n",
    "dfs = pd.read_html(page.text)\n",
    "\n",
    "\n",
    "bots_table = dfs[0]\n",
    "bots_table.loc[:,'Username']\n",
    "\n",
    "for username in bots_table.loc[:,'Username']:\n",
    "    full_list_bot_usrnames.append(username)\n",
    "    # usrname_url = \"https://www.reddit.com\" + username\n",
    "    # print(usrname_url) \n",
    "    \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing a webpage that has two tables of bot accounts.\n",
    "page = requests.get('https://www.reddit.com/r/botwatch/comments/1wg6f6/bot_list_i_built_a_bot_to_find_other_bots_so_far/cf1nu8p/', headers=headers)\n",
    "soup = bs4.BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "dfs = pd.read_html(page.text)\n",
    "\n",
    "# Appending the first dataframe of the firt table to the second dataframe of the second table.\n",
    "total= dfs[0].append(dfs[1]) \n",
    "\n",
    "\n",
    "for username in total.loc[:,'User']:\n",
    "    # usrname_url = \"https://www.reddit.com\" + username\n",
    "    # print(usrname_url) \n",
    "\n",
    "    # Checking if the bot account username is already in the list (from the table of bots in the previous list)\n",
    "    if username not in full_list_bot_usrnames:\n",
    "        full_list_bot_usrnames.append(username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of bot accounts 408\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of bot accounts\", len(full_list_bot_usrnames))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e1c550a6079a4718d0a11530d69d7c3ad84a77e0ac4995e256c56e02c9b89fc8"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
